
* **HYPERPARAMETRIZATION**

### Hyperparameterization

There are six main approaches to hyperparameter optimization which include:

* manual search, 
* grid search, 
* random search, 
* evolutionary algorithms, 
* Bayesian optimization, and 
* gradient based methods. 

Here, we would analyse **Bayesian Alternatives**. 

There are many open source implementations available for experimenting with Bayesian Optimisation, including (but not limited to):

* **HyperOpt**: Sequential model-based optimization is a Bayesian optimization technique that uses information from past trials to inform the next set of hyperparameters to explore, and there are two variants of this algorithm used in practice: (i) one based on the Gaussian process and the other on (ii) the Tree Parzen Estimator. The HyperOpt package implements the Tree Parzen Estimator algorithm.