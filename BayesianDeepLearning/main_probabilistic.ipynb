{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook guides through calibration function development using published data (S. De Vito et al., Sensors and Actuators B: Chemical, Volume 129, Issue 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libriaries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tfk = tf.keras\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['lines.linewidth'] = 1.0\n",
    "plt.rcParams['font.size'] = 6.0\n",
    "plt.rcParams['axes.titlesize'] = 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Functions\n",
    "\n",
    "Define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions.\n",
    "scaler = StandardScaler() # Define standard scaler instance.\n",
    "detector = IsolationForest(n_estimators=1000, behaviour=\"deprecated\", contamination=\"auto\", random_state=0) # Define outlier detector instance.\n",
    "lin_reg = LinearRegression() # Define linear regression instance.\n",
    "neg_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x) # Define negative logarithmic likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Data is scaled before analysis. In particular, standard scaling provides better results with respect to R2 score and explained variance compared with unscaled analysis. No imputation is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-42.602261</td>\n",
       "      <td>1034.871853</td>\n",
       "      <td>-113.434193</td>\n",
       "      <td>2.874622</td>\n",
       "      <td>900.022746</td>\n",
       "      <td>59.912031</td>\n",
       "      <td>860.794701</td>\n",
       "      <td>34.725237</td>\n",
       "      <td>1557.502959</td>\n",
       "      <td>906.415216</td>\n",
       "      <td>16.023040</td>\n",
       "      <td>34.424144</td>\n",
       "      <td>-5.533866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>83.726787</td>\n",
       "      <td>302.077005</td>\n",
       "      <td>193.392727</td>\n",
       "      <td>38.174135</td>\n",
       "      <td>312.298785</td>\n",
       "      <td>151.045512</td>\n",
       "      <td>298.766662</td>\n",
       "      <td>123.090508</td>\n",
       "      <td>411.689646</td>\n",
       "      <td>394.913480</td>\n",
       "      <td>40.798168</td>\n",
       "      <td>46.229254</td>\n",
       "      <td>36.066394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>918.250000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>4.481885</td>\n",
       "      <td>736.750000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>723.062500</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1421.375000</td>\n",
       "      <td>670.062500</td>\n",
       "      <td>16.575000</td>\n",
       "      <td>28.275001</td>\n",
       "      <td>0.880123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.300000</td>\n",
       "      <td>1038.375000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>8.224492</td>\n",
       "      <td>908.375000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>850.375000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1576.750000</td>\n",
       "      <td>880.625000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>41.675000</td>\n",
       "      <td>1.080659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>1176.937500</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>13.137205</td>\n",
       "      <td>1088.250000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1014.375000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>1746.937500</td>\n",
       "      <td>1138.000000</td>\n",
       "      <td>28.350000</td>\n",
       "      <td>53.543750</td>\n",
       "      <td>1.355107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.100000</td>\n",
       "      <td>2039.750000</td>\n",
       "      <td>1189.000000</td>\n",
       "      <td>40.260061</td>\n",
       "      <td>1776.250000</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>1940.750000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>2746.000000</td>\n",
       "      <td>2474.750000</td>\n",
       "      <td>44.600000</td>\n",
       "      <td>85.150002</td>\n",
       "      <td>2.180639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CO(GT)  PT08.S1(CO)     NMHC(GT)     C6H6(GT)  PT08.S2(NMHC)  \\\n",
       "count  4422.000000  4422.000000  4422.000000  4422.000000    4422.000000   \n",
       "mean    -42.602261  1034.871853  -113.434193     2.874622     900.022746   \n",
       "std      83.726787   302.077005   193.392727    38.174135     312.298785   \n",
       "min    -200.000000  -200.000000  -200.000000  -200.000000    -200.000000   \n",
       "25%       0.400000   918.250000  -200.000000     4.481885     736.750000   \n",
       "50%       1.300000  1038.375000  -200.000000     8.224492     908.375000   \n",
       "75%       2.200000  1176.937500  -200.000000    13.137205    1088.250000   \n",
       "max       8.100000  2039.750000  1189.000000    40.260061    1776.250000   \n",
       "\n",
       "           NOx(GT)  PT08.S3(NOx)      NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "count  4422.000000   4422.000000  4422.000000   4422.000000  4422.000000   \n",
       "mean     59.912031    860.794701    34.725237   1557.502959   906.415216   \n",
       "std     151.045512    298.766662   123.090508    411.689646   394.913480   \n",
       "min    -200.000000   -200.000000  -200.000000   -200.000000  -200.000000   \n",
       "25%      30.000000    723.062500    39.000000   1421.375000   670.062500   \n",
       "50%      85.000000    850.375000    81.000000   1576.750000   880.625000   \n",
       "75%     149.000000   1014.375000   112.000000   1746.937500  1138.000000   \n",
       "max     631.000000   1940.750000   233.000000   2746.000000  2474.750000   \n",
       "\n",
       "                 T           RH           AH  \n",
       "count  4422.000000  4422.000000  4422.000000  \n",
       "mean     16.023040    34.424144    -5.533866  \n",
       "std      40.798168    46.229254    36.066394  \n",
       "min    -200.000000  -200.000000  -200.000000  \n",
       "25%      16.575000    28.275001     0.880123  \n",
       "50%      23.000000    41.675000     1.080659  \n",
       "75%      28.350000    53.543750     1.355107  \n",
       "max      44.600000    85.150002     2.180639  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and keep only first six months.\n",
    "data = pd.read_excel(\"data/AirQualityUCI.xlsx\")\n",
    "data = data[data[\"Date\"] <= \"2004-09-10\"] # Keep only the first (drift-free) six months.\n",
    "\n",
    "# Visualize data summary.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns and remove rows with missing values.\n",
    "columns = [\"PT08.S1(CO)\", \"PT08.S3(NOx)\", \"PT08.S4(NO2)\", \"PT08.S5(O3)\", \"T\", \"AH\", \"CO(GT)\", \"C6H6(GT)\", \"NOx(GT)\", \"NO2(GT)\"]\n",
    "data = data[columns].dropna(axis=0)\n",
    "\n",
    "# Scale data to zero mean and unit variance.\n",
    "X_t = scaler.fit_transform(data)\n",
    "\n",
    "# Optional: Impute missing values.\n",
    "# X_t = imputer.fit_transform(X_t)\n",
    "\n",
    "# Remove outliers.\n",
    "is_inlier = detector.fit_predict(X_t)\n",
    "X_t = X_t[(is_inlier)>0,:]\n",
    "\n",
    "# Restore frame.\n",
    "dataset = pd.DataFrame(X_t, columns=columns)\n",
    "\n",
    "# Select labels for inputs and outputs.\n",
    "inputs = [\"PT08.S1(CO)\", \"PT08.S3(NOx)\", \"PT08.S4(NO2)\", \"PT08.S5(O3)\", \"T\", \"AH\"]\n",
    "outputs = [\"CO(GT)\", \"C6H6(GT)\", \"NOx(GT)\", \"NO2(GT)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling\n",
    "First, a data pipline is to be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some hyperparameters.\n",
    "n_epochs = 50\n",
    "n_samples = dataset.shape[0]\n",
    "batch_size = np.floor(n_samples/10)\n",
    "buffer_size = n_samples\n",
    "\n",
    "# Define training and test data sizes.\n",
    "n_train = int(0.7*dataset.shape[0])\n",
    "\n",
    "# Define dataset instance.\n",
    "data = tf.data.Dataset.from_tensor_slices((dataset[inputs].values, dataset[outputs].values)) # Define input/output data.\n",
    "data = data.shuffle(n_samples, reshuffle_each_iteration=True) # Shuffle.\n",
    "\n",
    "#Â Define train and test data instances.\n",
    "data_train = data.take(n_train).batch(batch_size).repeat(n_epochs)\n",
    "data_test = data.skip(n_train).batch(1).repeat(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "A probabilistic neural network with two layers is used as machine learning algorithm. In a first iteration, only **aleotoric variability** is considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/erikapat/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n"
     ]
    }
   ],
   "source": [
    "# Define prior for Gaussians.\n",
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(len(outputs), dtype=tf.float64), scale=1.0), reinterpreted_batch_ndims=1)\n",
    "\n",
    "# Define model instance.\n",
    "model = tfk.Sequential([\n",
    "    tfk.layers.InputLayer(input_shape=(len(inputs),), name=\"input\"), # Input layer.\n",
    "    tfk.layers.Dense(10, activation=\"relu\", name=\"dense_1\"), # First layer with ten nodes and non-linear activation.\n",
    "    tfk.layers.Dense(tfp.layers.MultivariateNormalTriL.params_size(len(outputs)), activation=None, name=\"distribution_weights\"),\n",
    "    tfp.layers.MultivariateNormalTriL(len(outputs), activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior, weight=1/n_samples), name=\"output\")\n",
    "], name=\"model\")\n",
    "\n",
    "# Compile model.\n",
    "model.compile(optimizer=\"adam\", loss=neg_log_likelihood) # Negative logarithmic likelihood as loss function and ADAM optimizer.\n",
    "\n",
    "# Run training session.\n",
    "model.fit(data_train, epochs=n_epochs, validation_data=data_test, verbose=False)\n",
    "\n",
    "# Describe model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training session.\n",
    "fig = plt.figure(figsize=(2.95,2.95))\n",
    "fig.tight_layout()\n",
    "plt.xlim(0, np.round(len(model.history.epoch)+4,-1))\n",
    "plt.ylim(-1, 5)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"negative logarithmic likelihood\")\n",
    "plt.plot(list(map(lambda x: x + 1, model.history.epoch)), model.history.history[\"loss\"], label=\"training\", color=plt.cm.viridis(0.3))\n",
    "plt.plot(list(map(lambda x: x + 1, model.history.epoch)), model.history.history[\"val_loss\"], label=\"validation\", color=plt.cm.viridis(0.6))\n",
    "plt.legend(frameon=False, loc=0)\n",
    "plt.savefig('./figures/metrics_probabilistic_aleotoric',dpi=900,transparent=True,orientation='landscape',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict.\n",
    "samples = 500\n",
    "iterations = 10\n",
    "test_iterator = tf.compat.v1.data.make_one_shot_iterator(data_test)\n",
    "X_true, Y_true, Y_pred = np.empty(shape=(samples,len(inputs))), np.empty(shape=(samples,len(outputs))), np.empty(shape=(samples,len(outputs),iterations))\n",
    "for i in range(samples):\n",
    "    features, labels = test_iterator.get_next()\n",
    "    X_true[i,:] = features\n",
    "    Y_true[i,:] = labels.numpy()\n",
    "    for k in range(iterations):\n",
    "        Y_pred[i,:,k] = model.predict(features)\n",
    "        \n",
    "# Calculate mean and standard deviation.\n",
    "Y_pred_m = np.mean(Y_pred, axis=-1)\n",
    "Y_pred_s = np.std(Y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine slope.\n",
    "slope = lin_reg.fit(Y_true.flatten().reshape(-1, 1), Y_pred_m.flatten().reshape(-1, 1))\n",
    "\n",
    "# Perform predictions.\n",
    "Y_syn = np.linspace(-10, 10, 10)\n",
    "Y_syn_p = slope.predict(Y_syn.reshape(-1, 1))\n",
    "\n",
    "# Plot predictions vs. true values.\n",
    "fig = plt.figure(figsize=(2.95,2.95))\n",
    "fig.tight_layout()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(r\"Y$_{data}$\")\n",
    "ax.set_ylabel(r\"Y$_{model}$\")\n",
    "ax.set_xlim(-4.0, 4.0)\n",
    "ax.set_ylim(-4.0, 4.0)\n",
    "ax.plot(Y_syn, Y_syn_p, \":\", color=\"k\", label=r\"$\\beta$ = \"+str(np.round(slope.coef_[0][0],2)))\n",
    "ax.plot([-10,10], [-10,10], \"-\", color=\"k\")\n",
    "ax.plot(Y_true.flatten(), Y_pred_m.flatten(), color=plt.cm.viridis(0.6), marker=\".\", alpha=1.0, mec='k', linestyle=\"\")\n",
    "plt.legend(frameon=False, loc=4, ncol=1)\n",
    "plt.savefig('./figures/congruency_probabilistic_aleotoric',dpi=900,transparent=True,orientation='landscape',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "A probabilistic neural network with two layers is used as machine learning algorithm. In a first iteration, **aleotoric and epistemic variability** is considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prior for Gaussians.\n",
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(len(outputs), dtype=tf.float64), scale=1.0), reinterpreted_batch_ndims=1)\n",
    "\n",
    "# Define model instance.\n",
    "model = tfk.Sequential([\n",
    "    tfk.layers.InputLayer(input_shape=(len(inputs),), name=\"input\"), # Input layer.\n",
    "    tfp.layers.DenseFlipout(10, activation=\"relu\", name=\"dense_1\"), # First layer with ten nodes and non-linear activation.\n",
    "    tfp.layers.DenseFlipout(tfp.layers.MultivariateNormalTriL.params_size(len(outputs)), activation=None, name=\"distribution_weights\"),\n",
    "    tfp.layers.MultivariateNormalTriL(len(outputs), activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior, weight=1/n_samples), name=\"output\")\n",
    "], name=\"model\")\n",
    "\n",
    "# Compile model.\n",
    "model.compile(optimizer=\"adam\", loss=neg_log_likelihood) # MSE as loss function and ADAM optimizer.\n",
    "\n",
    "# Run training session.\n",
    "model.fit(data_train, epochs=n_epochs, validation_data=data_test, verbose=False)\n",
    "\n",
    "# Describe model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training session.\n",
    "fig = plt.figure(figsize=(2.95,2.95))\n",
    "fig.tight_layout()\n",
    "plt.xlim(0, np.round(len(model.history.epoch)+4,-1))\n",
    "plt.ylim(0, 500)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"negative logarithmic likelihood\")\n",
    "plt.plot(list(map(lambda x: x + 1, model.history.epoch)), model.history.history[\"loss\"], label=\"training loss\", color=plt.cm.viridis(0.3))\n",
    "plt.plot(list(map(lambda x: x + 1, model.history.epoch)), model.history.history[\"val_loss\"], label=\"validation loss\", color=plt.cm.viridis(0.6))\n",
    "plt.legend(frameon=False, loc=0)\n",
    "plt.savefig('./figures/metrics_probabilistic_aleotoric_epistemic',dpi=900,transparent=True,orientation='landscape',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
