{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**Natural Gradient Boosting (NGBoost)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a mix probability prediction with gradient boosting. It serves to create predictive uncertainty estimations. This methodology gives you the probability distribution P(y|x) of a prediction instead in a point estimation, that allows you calculate other statistics such as median, percentiles, confidence intervals in order to asses to more information about the esimation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Methodology**\n",
    "This algorithm uses base (weak) learners. It takes inputs x and outputs are used to form the conditional probability. Those base learners use scikit-learnâ€™s Decision Tree for a tree learner and Ridge regression for a linear learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install ngboost\n",
    "#!pip install ngboost\n",
    "#!pip install lightgbm\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.learners import default_tree_learner\n",
    "from ngboost.distns import Normal\n",
    "from ngboost.scores import MLE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataset = load_boston()\n",
    "X, y = dataset.data, dataset.target\n",
    "features = dataset.feature_names\n",
    " \n",
    "SEED = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of training dataset: 404\n",
      "The shape of testing dataset: 102\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=SEED)\n",
    "print('The shape of training dataset: {}'.format(X_train.shape[0]))\n",
    "print('The shape of testing dataset: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: R2 score on testing data: 79.40%\n",
      "[iter 0] loss=3.6582 val_loss=0.0000 scale=0.5000 norm=3.4016\n",
      "[iter 100] loss=3.0912 val_loss=0.0000 scale=1.0000 norm=3.7753\n",
      "[iter 200] loss=2.6952 val_loss=0.0000 scale=1.0000 norm=2.3972\n",
      "[iter 300] loss=2.3684 val_loss=0.0000 scale=1.0000 norm=1.8804\n",
      "NGBoost: R2 score on testing data: 79.86%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit and predict\n",
    "rf = RandomForestRegressor(n_estimators=400, random_state=SEED).fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print('Random Forest: R2 score on testing data: {:.2f}%'.format(100 * r2_score(y_test, y_pred)))\n",
    " \n",
    "# Fit and predict\n",
    "#lgb = LGBMRegressor(n_estimators=400, random_state=SEED).fit(X_train, y_train)\n",
    "#y_pred = lgb.predict(X_test)\n",
    "#print('LightGBM: R2 score on testing data: {:.2f}%'.format(100 * r2_score(y_test, y_pred)))\n",
    " \n",
    "# Fit and predict\n",
    "np.random.seed(SEED)\n",
    "ngb = NGBRegressor(n_estimators=400,\n",
    "                   Base=default_tree_learner, Dist=Normal, Score=MLE).fit(X_train, y_train)\n",
    "y_pred = ngb.predict(X_test)\n",
    "print('NGBoost: R2 score on testing data: {:.2f}%'.format(100 * r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that NGBoost seems to compite with RF without any hiperparametrization. Now, we show how to use the distribution obtained with NGBoost that is the advantage of this methodology over others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ngb = pd.DataFrame(ngb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: NGBoost 3.7137\n"
     ]
    }
   ],
   "source": [
    "# Check the results\n",
    "print('RMSE: NGBoost', round(sqrt(mean_squared_error(y_test,y_pred_ngb)),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NLL 2.7122353833092814\n"
     ]
    }
   ],
   "source": [
    "# test Negative Log Likelihood\n",
    "Y_dists = ngb.pred_dist(X_test)\n",
    "test_NLL = -Y_dists.logpdf(y_test.flatten()).mean()\n",
    "print('Test NLL', test_NLL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parameters of the distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y_0|x_0) is normally distributed with loc=17.54 and scale=2.36\n",
      "P(y_1|x_1) is normally distributed with loc=22.55 and scale=2.39\n"
     ]
    }
   ],
   "source": [
    "obs_idx = [0,1]\n",
    "dist = ngb.pred_dist(X_test[obs_idx, :])\n",
    "print('P(y_0|x_0) is normally distributed with loc={:.2f} and scale={:.2f}'.format(dist.loc[0], dist.scale[0]))\n",
    "print('P(y_1|x_1) is normally distributed with loc={:.2f} and scale={:.2f}'.format(dist.loc[1], dist.scale[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **mean & std**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 2.679005\n",
      "standard deviation = 0.550311\n"
     ]
    }
   ],
   "source": [
    "print('mean = %f'% Y_dists.scale.mean())\n",
    "print('standard deviation = %f'%Y_dists.scale.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PIT**\n",
    "\n",
    "In an ideal fit we would expect the bars are close to the dotted line, indicate that it's a somewhat bad fit which is the same case as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ngboost.evaluation import *\n",
    "y_dists = ngb.pred_dist(X_test)\n",
    "pctles, observed, slope, intercept = calibration_regression(y_dists, y_test-min(y_test)+0.001)\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_pit_histogram(pctles, observed, label=\"CRPS\", linestyle = \"-\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature importance**\n",
    "\n",
    "Note: create a kernel with the requirements\n",
    "\n",
    "https://github.com/stanfordmlgroup/ngboost/blob/master/examples/inspections/Feature%20importance.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NGBRegressor' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-72d34c825b88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mngb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NGBRegressor' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "ngb.feature_importances_[0] ## this does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NGBRegressor' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1ef45fba5deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m feature_importance = pd.DataFrame({'feature':load_boston()['feature_names'], \n\u001b[0;32m----> 2\u001b[0;31m                                    'importance':ngb.feature_importances_[0]})\\\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature Importance Plot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NGBRegressor' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({'feature':load_boston()['feature_names'], \n",
    "                                   'importance':ngb.feature_importances_[0]})\\\n",
    "    .sort_values('importance',ascending=False).reset_index().drop(columns='index')\n",
    "fig, ax = plt.subplots()\n",
    "plt.title('Feature Importance Plot')\n",
    "sns.barplot(x='importance',y='feature',ax=ax,data=feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **More explanability with shap values**\n",
    "\n",
    "https://github.com/stanfordmlgroup/ngboost/blob/master/examples/inspections/SHAP%20plots.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the probability distributions by visualising\n",
    "Y_dists = ngb.pred_dist(X_val.drop(['SalePrice'],1))\n",
    "y_range = np.linspace(min(X_val.SalePrice), max(X_val.SalePrice), 200)\n",
    "dist_values = Y_dists.pdf(y_range).transpose()\n",
    "# plot index 0 and 114\n",
    "idx = 114\n",
    "plt.plot(y_range,dist_values[idx])\n",
    "plt.title(f\"idx: {idx}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': '/Users/erika/opt/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/boston_house_prices.csv'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the probability distributions by visualising\n",
    "Y_dists = ngb.pred_dist(dataset.drop(['SalePrice'],1))\n",
    "y_range = np.linspace(min(X_val.SalePrice), max(X_val.SalePrice), 200)\n",
    "dist_values = Y_dists.pdf(y_range).transpose()\n",
    "# plot index 0 and 114\n",
    "idx = 114\n",
    "plt.plot(y_range,dist_values[idx])\n",
    "plt.title(f\"idx: {idx}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dists.pdf(y_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the probability distributions by visualising\n",
    "Y_dists = ngb.pred_dist(X_test)\n",
    "y_range = np.linspace(min(y_test), max(y_test), X_test.shape[0])\n",
    "dist_values = Y_dists.pdf(y_range).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot index 0 and 114\n",
    "idx = 4\n",
    "plt.plot(y_range,dist_values[idx])\n",
    "plt.title(f\"idx: {idx}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "* NGBoost Explained [[here]](https://dkopczyk.quantee.co.uk/ngboost-explained/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Other material to read**\n",
    "\n",
    "* Dropout As a Bayesian Approximation: Representing Model Uncertainty in Deep Learning\n",
    "https://arxiv.org/abs/1506.02142\n",
    "\n",
    "* Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles\n",
    "https://arxiv.org/abs/1612.01474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
