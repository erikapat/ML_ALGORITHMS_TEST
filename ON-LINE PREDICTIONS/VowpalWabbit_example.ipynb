{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VowpalWabbit Text Classification**\n",
    "\n",
    "A movie production company wants to build a real time IMDB review extraction and prediction system. The task is to predict whether a particular review is positive or negative. The data provided has only the actual reviews as text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Install Vowpal Wabbit**\n",
    "\n",
    "Installing vowpal-wabbit package on Ubuntu is as easy as:\n",
    "\n",
    "1. Follow the instructions here: https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Dependencies\n",
    "\n",
    "2. Run the following commands on terminal:\n",
    "\n",
    "    `sudo apt-get update`\n",
    "    \n",
    "    `sudo apt-get install vowpal-wabbit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vowpal_wabbit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CHECK IF THE INSTALLATION IS WORKING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!vw --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](fig/ex.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LOAD DATA**\n",
    "\n",
    "Download the data from: http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Read the train Data\n",
    "path_to_movies = os.getcwd() + '/data/'\n",
    "reviews_train = load_files(os.path.join(path_to_movies, 'train'))\n",
    "text_train, y_train = reviews_train.data, reviews_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in training data: 75000\n",
      "[12500 12500 50000]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents in training data: %d\" % len(text_train))\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"i seen this poor done comic film.but it would been better if they used a family that wasn't based on nothing.the movie starts as Denise finds a dinosaur bone in his back yard,and a fake<br /><br />who claims to be a dinosaur hunter comes to stay with the family.and he is real annoying too.the film did not deliver much laughs.the only two funny things in the movie was when Denise tries to sneak that fudge candy to his room and the scene where Mr Wilson's washer overflowed.it would be a better film if it involved a different character.the 93 version was a real one.this one wasn't a Denise the menace at all. and i saw this one 2 or 3 times a month when it was on HBO.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[74000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12500 12500 50000]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Treatment**\n",
    "\n",
    "Basic removal of all the words with less than three characters (like ‘is’, ‘in’ etc.) because these do not add any valuable information to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def to_vw_format(document, label=None):\n",
    "      return str(label or '') + ' |text ' + ' '.join(re.findall('\\w{3,}', document.lower())) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-1 |text full then unknown actors tsf great big cuddly romp film the idea bunch bored teenagers ripping off the local sink factory odd enough but add the black humour that forsyth are good and your for real treat the comatose van driver itself worth seeing and the canal side chase just too real anything but funny and for anyone who lived glasgow great know where that film\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_vw_format(str(text_train[0]), 1 if y_train[0] == 1 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Divide the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train data to train and validation sets\n",
    "train_size = int(0.7 * len(text_train))\n",
    "train, train_labels = text_train[:train_size], y_train[:train_size]\n",
    "valid, valid_labels = text_train[train_size:], y_train[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and save in vowpal wabbit format\n",
    "with open('movie_reviews_train.vw', 'w') as vw_train_data:\n",
    "    for text, target in zip(train, train_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))\n",
    "with open('movie_reviews_valid.vw', 'w') as vw_train_data:\n",
    "    for text, target in zip(valid, valid_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52500, 22500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels), len(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 |text full then unknown actors tsf great big cuddly romp film the idea bunch bored teenagers ripping off the local sink factory odd enough but add the black humour that forsyth are good and your for real treat the comatose van driver itself worth seeing and the canal side chase just too real anything but funny and for anyone who lived glasgow great know where that film\n",
      "-1 |text amount disappointment getting these days seeing movies like partner jhoom barabar and now heyy babyy gonna end habit seeing first day shows the movie utter disappointment because had the potential become laugh riot only the xc3 xa9butant director sajid khan hadn tried too many things only saving grace the movie were the last thirty minutes which were seriously funny elsewhere the movie fails miserably first half was desperately been tried look funny but wasn next minutes were emotional and looked totally artificial and illogical when you are out for movie like this you don expect much logic but all the flaws tend appear when you don enjoy the movie and thats the case with heyy babyy acting good but thats not enough keep one interested for the positives you can take hot actresses last minutes some comic scenes good acting the lead cast and the baby only problem that these things not come together properly make good movie anyways read somewhere that isn copy three men and baby but think would have been better was\n"
     ]
    }
   ],
   "source": [
    "!head -2 movie_reviews_train.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TRAINING**\n",
    "\n",
    "* **-d** This is used to include the  path to train the data for the command line.\n",
    "* **–loss_function** This is used to declare the loss function (e.g. squared, logistic, hinge etc.).\n",
    "* **-f**  This is used to save the model for using it on a different dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a logistic regression for predicting the sentiment of a review\n",
    "#logistic|hinge\n",
    "!vw -d movie_reviews_train.vw --loss_function hinge -f movie_reviews_model.vw --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TESTING**\n",
    "\n",
    "* **-i** Read the model from the given file\n",
    "* **-t -d** Declare that we are dealing with dataset without labels (test) at this path\n",
    "* **-p** Save predictions to this file\n",
    "* **–quiet** Do not print any steps taken for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vw -i movie_reviews_model.vw -t -d movie_reviews_valid.vw -p movie_valid_pred.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2128\n"
     ]
    }
   ],
   "source": [
    "with open('movie_valid_pred.txt') as pred_file:\n",
    "    valid_prediction = [float(label) for label in pred_file.readlines()]\n",
    "    print(\"Accuracy: {}\".format(round(accuracy_score(valid_labels, [int(pred_prob > 0) for pred_prob in valid_prediction]), 5)))\n",
    "    #print(\"AUC: {}\".format(round(roc_auc_score(valid_labels, valid_prediction), 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **N-GRAMS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = movie_reviews_model_bigram.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = movie_reviews_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.0000      132\n",
      "0.492365 0.291584            2            2.0  -1.0000  -1.0831      350\n",
      "0.715313 0.938260            4            4.0   1.0000  -1.6409      224\n",
      "0.698638 0.681964            8            8.0  -1.0000  -0.9543      468\n",
      "0.448672 0.198706           16           16.0  -1.0000  -1.9253      350\n",
      "0.604503 0.760333           32           32.0  -1.0000  -1.1030      336\n",
      "0.570287 0.536072           64           64.0  -1.0000  -1.9983      374\n",
      "0.498139 0.425990          128          128.0  -1.0000  -1.5878      172\n",
      "0.474052 0.449966          256          256.0  -1.0000  -0.8328      308\n",
      "0.467471 0.460890          512          512.0  -1.0000  -0.8026      226\n",
      "0.449753 0.432036         1024         1024.0  -1.0000  -1.0714      170\n",
      "0.448099 0.446446         2048         2048.0   1.0000  -0.9688      252\n",
      "0.444569 0.441039         4096         4096.0  -1.0000  -5.9594      602\n",
      "0.424249 0.403929         8192         8192.0  -1.0000  -0.3499      174\n",
      "0.418496 0.412743        16384        16384.0  -1.0000  -4.7563      344\n",
      "0.397323 0.376149        32768        32768.0  -1.0000   4.1462     1108\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 52500\n",
      "passes used = 1\n",
      "weighted example sum = 52500.000000\n",
      "weighted label sum = -35008.000000\n",
      "average loss = 0.383844\n",
      "best constant = -1.609987\n",
      "best constant's loss = 0.450439\n",
      "total feature number = 19419908\n"
     ]
    }
   ],
   "source": [
    "!vw -d movie_reviews_train.vw --loss_function logistic --ngram 2 -f movie_reviews_model_bigram.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vw -i movie_reviews_model.vw -t -d movie_reviews_valid.vw -p movie_reviews_model_bigram.vw --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2128\n"
     ]
    }
   ],
   "source": [
    "with open('movie_reviews_model_bigram.vw') as pred_file:\n",
    "    valid_prediction = [float(label) for label in pred_file.readlines()]\n",
    "    print(\"Accuracy: {}\".format(round(accuracy_score(valid_labels, [int(pred_prob > 0) for pred_prob in valid_prediction]), 5)))\n",
    "    #print(\"AUC: {}\".format(round(roc_auc_score(valid_labels, valid_prediction), 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Interpretability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = movie_reviews_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.0000      132\n",
      "0.492365 0.291584            2            2.0  -1.0000  -1.0831      350\n",
      "0.715313 0.938260            4            4.0   1.0000  -1.6409      224\n",
      "0.698638 0.681964            8            8.0  -1.0000  -0.9543      468\n",
      "0.448672 0.198706           16           16.0  -1.0000  -1.9253      350\n",
      "0.604503 0.760333           32           32.0  -1.0000  -1.1030      336\n",
      "0.570287 0.536072           64           64.0  -1.0000  -1.9983      374\n",
      "0.498139 0.425990          128          128.0  -1.0000  -1.5878      172\n",
      "0.474052 0.449966          256          256.0  -1.0000  -0.8328      308\n",
      "0.467471 0.460890          512          512.0  -1.0000  -0.8026      226\n",
      "0.449753 0.432036         1024         1024.0  -1.0000  -1.0714      170\n",
      "0.448099 0.446446         2048         2048.0   1.0000  -0.9688      252\n",
      "0.444569 0.441039         4096         4096.0  -1.0000  -5.9594      602\n",
      "0.424249 0.403929         8192         8192.0  -1.0000  -0.3499      174\n",
      "0.418496 0.412743        16384        16384.0  -1.0000  -4.7563      344\n",
      "0.397323 0.376149        32768        32768.0  -1.0000   4.1462     1108\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 52500\n",
      "passes used = 1\n",
      "weighted example sum = 52500.000000\n",
      "weighted label sum = -35008.000000\n",
      "average loss = 0.383844\n",
      "best constant = -1.609987\n",
      "best constant's loss = 0.450439\n",
      "total feature number = 19419908\n"
     ]
    }
   ],
   "source": [
    "!vw -d movie_reviews_train.vw --loss_function logistic --ngram 2 --invert_hash movie_reviews_readable_model_bigram.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **REGULARIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "using l1 regularization = 5e-05\n",
      "using l2 regularization = 5e-05\n",
      "final_regressor = movie_reviews_model_bigram.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = movie_reviews_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.0000      132\n",
      "0.492415 0.291683            2            2.0  -1.0000  -1.0827      350\n",
      "0.715097 0.937779            4            4.0   1.0000  -1.6396      224\n",
      "0.698451 0.681805            8            8.0  -1.0000  -0.9516      468\n",
      "0.448968 0.199485           16           16.0  -1.0000  -1.9166      350\n",
      "0.603455 0.757942           32           32.0  -1.0000  -1.1053      336\n",
      "0.569885 0.536316           64           64.0  -1.0000  -1.9675      374\n",
      "0.497651 0.425417          128          128.0  -1.0000  -1.5422      172\n",
      "0.472383 0.447116          256          256.0  -1.0000  -0.8780      308\n",
      "0.467880 0.463376          512          512.0  -1.0000  -0.8267      226\n",
      "0.449276 0.430672         1024         1024.0  -1.0000  -0.8042      170\n",
      "0.447374 0.445472         2048         2048.0   1.0000  -1.0384      252\n",
      "0.452488 0.457602         4096         4096.0  -1.0000  -3.1477      602\n",
      "0.442847 0.433207         8192         8192.0  -1.0000  -0.5083      174\n",
      "0.452814 0.462780        16384        16384.0  -1.0000  -2.6098      344\n",
      "0.452753 0.452693        32768        32768.0  -1.0000  -1.9075     1108\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 52500\n",
      "passes used = 1\n",
      "weighted example sum = 52500.000000\n",
      "weighted label sum = -35008.000000\n",
      "average loss = 0.458631\n",
      "best constant = -1.609987\n",
      "best constant's loss = 0.450439\n",
      "total feature number = 19419908\n"
     ]
    }
   ],
   "source": [
    "!vw -d movie_reviews_train.vw --l1 0.00005 --l2 0.00005 --loss_function logistic --ngram 2 -f movie_reviews_model_bigram.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
